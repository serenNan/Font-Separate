# Font-Separate 项目开发历程

**项目名称**：Font-Separate - 文档图像智能分离系统
**开发周期**：2025年9月30日 - 2025年10月5日（6天）
**提交次数**：12次
**代码规模**：约2000行

---

## 一、项目背景

### 需求说明

从历史文档扫描件中自动分离：
1. 表格区域
2. 手写体文字
3. 印刷体文字

### 样本特点

测试样本为历史档案扫描件（Pictures/原始.jpg），具有以下特点：
- 左侧：印刷表格（多行多列）
- 右侧：手写批注（毛笔字）
- 纸张老化，有污渍和破损
- 墨迹严重褪色，对比度低
- 表格线模糊且有断裂

---

## 二、开发过程

### 第一天：基础架构（9月30日）

#### 提交1：初始化项目（350b5e4）

创建项目目录，添加测试图片和需求文档。

#### 提交2：完成基础架构（d387ece）

搭建了完整的Web应用框架：
- Flask后端（app.py，122行）
- 表格检测器（utils/table_detector.py，448行）
- 前端界面（HTML/CSS/JavaScript）

表格检测算法实现：
```
灰度化 → Otsu二值化 → 形态学分离横竖线 → Hough变换检测直线 →
线条合并 → 交叉点聚类 → 定位表格区域
```

遇到的问题：
1. 无法区分数据表格和空白表格
2. 复杂表格被错误分割

---

### 第二天：手写体分类第一次尝试（10月2日）

#### 提交3：完成区分但是效果很差（17bdfad）

实现了基于形态学特征的文字分类器（332行）。

算法思路：
1. 笔画宽度变异系数 - 手写体笔画粗细变化大，印刷体均匀
2. 圆形度 - 手写体形状不规则，印刷体规整
3. 像素密度 - 手写体墨迹浓度不均

使用骨架化和距离变换提取笔画特征：
```python
skeleton = cv2.ximgproc.thinning(roi_binary)
dist_transform = cv2.distanceTransform(roi_binary, cv2.DIST_L2, 5)
stroke_widths = dist_transform[skeleton > 0]
stroke_width_cv = std / mean
```

分类规则：
```
手写体：stroke_cv > 0.35 且 circularity < 0.3
印刷体：stroke_cv < 0.25 且 circularity > 0.5
```

提交注释写的是"完成区分但是效果很差"，准确度只有约30%。

核心问题：
- 历史文档的印刷体和手写体特征差异太小
- 笔画宽度变异系数受图像质量影响极大
- 圆形度特征对模糊图像完全失效

#### 提交4：图片预处理（d075836）

尝试通过增强预处理来改善效果：
```
双边滤波（保边去噪） → 锐化增强 → CLAHE对比度增强 → 自适应阈值二值化
```

新增文件：
- preprocess_text.py（54行）
- utils/text_extractor.py（294行）

准确度从30%提升到约40%，但依然很差。

---

### 第三天：算法探索（10月3日）

#### 提交5：进一步去噪（82dc3ae）

创建了5个实验性脚本，尝试不同的方案：

1. **advanced_denoise.py（238行）** - 历史文书专用去噪
   - 基于连通组件特征分析
   - 区分文字和污渍
   - 过滤参数：面积、宽高比、紧凑度、圆形度

   这个去噪算法效果不错，成功去除了大部分污渍。

2. **classify_preprocessed.py（176行）** - 预处理后分类

3. **classify_yolo.py（117行）** - 尝试YOLO目标检测
   需要训练数据，放弃

4. **detect_text_craft.py（107行）** - 尝试CRAFT文字检测
   速度慢，效果一般

5. **detect_text_paddleocr.py（105行）** - 尝试PaddleOCR
   准确度不理想

结论：深度学习方案需要大量训练数据，传统形态学方法无法准确区分手写/印刷体。

#### 提交6：进一步区分，效果60分吧（9e0286e）

放弃形态学特征，改用EasyOCR。

重大技术路线转变：
- 删除所有实验脚本
- 重写text_classifier.py（从321行简化到93行，代码量减少72%）

新算法：
```python
# 初始化EasyOCR
reader = easyocr.Reader(['ch_sim', 'en'], gpu=False)

# 检测文字
results = reader.readtext(image_path)

# 基于位置分类
split_x = w * 0.45  # 45%分界线
if center_x < split_x:
    → 印刷体（左侧表格）
else:
    → 手写体（右侧批注）

# 过滤异常框
if aspect_ratio > 5 or aspect_ratio < 0.2:
    continue  # 表格线残留
```

核心思路：利用文档布局特点（左侧印刷，右侧手写），而不是分析文字本身的特征。

准确度提升到约60%，但依然存在大量误判。提交注释写的是"进一步区分，效果60分吧"，语气透露出不太满意。

---

### 第四天：表格检测优化（10月4日）

#### 提交7：表格分离完善（31ad7c5）

表格检测的重大突破：引入内容密度分析。

核心创新：
```python
def calculate_content_density(region_img, binary_img):
    """计算表格区域的内容密度"""
    black_pixels = np.sum(binary_img == 255)
    total_area = region_img.shape[0] * region_img.shape[1]
    density = black_pixels / total_area

    # 连通组件数量
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_img)
    component_count = num_labels - 1

    return density, component_count

def classify_table_type(content_info, h_lines, v_lines):
    """根据内容密度分类表格类型"""
    density = content_info['density']
    component_count = content_info['component_count']

    # 空白表格：密度很低，组件很少
    if density < 0.01 and component_count < 3:
        return 'empty_table'

    # 标题框：密度很高或线条很少
    if density > 0.20 and component_count < 30:
        return 'title_box'
    if h_lines <= 1 and v_lines <= 3:
        return 'title_box'

    # 数据表格：其他情况
    return 'data_table'
```

表格分离准确度从约50%提升到85%，这是第一个真正成功的功能。

#### 提交8：表格进一步完善（324d837）

微调内容密度阈值，优化分类规则。

#### 提交9：网站部分完善（c7f949f）

删除旧的测试代码，优化前端展示逻辑。

---

### 第五天：颜色分类尝试（10月4日晚）

#### 提交10：颜色区分，效果较好（f33d67f）

新增颜色分类功能，试图作为手写/印刷体分类的替代方案。

算法设计：
```python
# 1. EasyOCR检测文字区域
results = reader.readtext(image_path)

# 2. 提取文字颜色
gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
_, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
text_pixels = roi[mask > 0]
median_color = np.median(text_pixels, axis=0)

# 3. 转换到Lab色彩空间
color_lab = cv2.cvtColor(color_bgr, cv2.COLOR_BGR2Lab)

# 4. K-Means聚类（自动确定最佳k值）
kmeans = KMeans(n_clusters=k, random_state=42)
labels = kmeans.fit_predict(colors)
```

特点：
- 完全自适应，不预设黑/蓝/红等固定颜色
- 使用轮廓系数自动确定最佳聚类数（2-6类）
- Lab色彩空间更符合人类感知
- 使用中位数而非均值（抗离群点）

提交注释写的是"颜色区分，效果较好"，这是开发过程中唯一一次出现"较好"的评价。

但是后来实际测试发现，这个评价过于乐观了。

---

### 第六天：Web界面完善（10月5日）

#### 提交11：添加功能选择（fadea8e）

Web界面集成三种处理模式：
1. /process_table - 表格分离
2. /process_text - 手写/印刷体分类
3. /process_color - 颜色分类

用户可以选择需要的功能，每种功能独立处理。

#### 提交12：完善网站加载图片逻辑（ba2c3c5）

优化前端图片加载和展示逻辑。

---

## 三、深度测试与问题发现（10月5日下午）

在完成所有功能后，进行了详细的测试。

### 表格分离测试

测试结果：85%准确度，符合预期。

成功案例：
- 正确识别多个数据表格
- 过滤空白表格和标题框
- 通过垂直线间隙分割多表格

失败案例：
- 倾斜表格检测失败（未实现倾斜校正）
- 部分模糊线条漏检

### 手写/印刷体分类测试

EasyOCR + 位置分类方案测试：
- 检测到89个文字区域
- 准确度约60%

问题：
- 强依赖文档布局（左侧印刷，右侧手写）
- 分界线位置（45%）需要针对不同文档调整
- 无法处理混合布局

### 颜色分类测试

这是最大的失败。

实际测试数据：
```
检测到89个文字区域
提取到78个有效颜色特征

聚类结果（K=3）：
类别0: 27个区域, RGB[175, 166, 158], HSV[14, 25, 175], gray-like
类别1: 16个区域, RGB[118, 120, 119], HSV[75, 4, 120], gray-like
类别2: 35个区域, RGB[186, 187, 183], HSV[38, 5, 187], gray-like
```

关键发现：
- 所有类别都被识别为gray-like（灰色）
- 饱和度只有4-25（接近无色彩）
- 三个类别都是极其相近的灰色调

根本原因：历史文档墨迹严重褪色
- 原本的黑色墨水 → 深灰色（RGB 120左右）
- 原本的蓝色墨水 → 中灰色（RGB 160-180）
- 原本的红色印章 → 褐灰色（RGB 170-190）

算法缺陷：
```python
# Otsu二值化对褪色文档完全失效
_, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
```

Otsu假设图像有明显的前景/背景双峰分布，但褪色文档的墨迹和背景都是灰色，峰值重叠，导致分割不准确，混入大量背景像素。

### 改进尝试

尝试1：亮度分类（替代颜色）
```python
# 只提取亮度特征，不管颜色
gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
text_pixels = gray[mask > 0]
brightness = np.mean(text_pixels)
```

结果：
- 亮度范围93-221（最深的墨迹都已经达到93，远离纯黑0）
- 大部分墨迹亮度在120-180之间
- 分类界限模糊，准确度约40%

尝试2：墨迹深度分类（鲁棒算法）
```python
# 使用固定阈值，不用Otsu
_, mask = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY_INV)

# 腐蚀去除边缘噪声
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
mask = cv2.erode(mask, kernel, iterations=2)

# 只分析最深的50%像素
sorted_indices = np.argsort(ink_pixels_gray)
darkest_indices = sorted_indices[:len(sorted_indices)//2]
```

结果：
- 墨迹亮度范围46-148（比之前好）
- 最深墨迹21（接近真实墨水）
- 聚类效果轮廓系数0.666（较好）
- 但是只检测到26/89个区域，漏检率70%

问题：阈值180太严格，很多褪色的墨迹（亮度>180）被当作背景过滤掉。

---

## 四、技术路线总结

### 手写/印刷体分类的演变

尝试1：形态学特征分类
- 笔画宽度变异系数
- 圆形度
- 像素密度
- 结果：30%准确度，完全失败

尝试2：增强预处理 + 形态学
- 双边滤波、锐化、CLAHE
- 自适应阈值
- 结果：40%准确度，依然失败

尝试3：EasyOCR + 位置分类
- 利用文档布局特点
- 代码从321行简化到93行
- 结果：60%准确度，勉强可用但不满意

### 颜色分类的演变

尝试1：颜色自适应聚类
- Lab色彩空间 + K-Means
- 结果：15%准确度，墨迹全部变成灰色

尝试2：亮度聚类
- 提取亮度特征
- 结果：40%准确度，界限模糊

尝试3：墨迹深度分类
- 固定阈值 + 腐蚀
- 只分析最深像素
- 结果：50%准确度，但漏检70%

---

## 五、失败原因分析

### 样本问题

历史文档严重老化：
- 墨迹严重褪色（最深的墨水亮度都>90）
- 所有颜色都退化成灰色（饱和度<30）
- 纸张泛黄、污渍、破损
- 表格线模糊断裂

### 算法局限

传统图像处理方法的天花板：
- 基于规则的特征提取对退化严重的图像失效
- Otsu二值化假设双峰分布，对褪色文档不适用
- 形态学特征受图像质量影响极大

### 需求难度

手写/印刷体区分本身就是困难问题：
- 在清晰的现代文档中都不容易
- 在退化的历史文档中几乎不可能（用传统方法）
- 需要深度学习模型

---

## 六、最终成果

### 可用功能

1. 表格分离：85%准确度
   - 基于Hough变换检测线条
   - 内容密度分析过滤空白表格
   - 可以直接使用

### 不可用功能

2. 手写/印刷体分类：60%准确度
   - EasyOCR + 位置分类
   - 强依赖文档布局
   - 需要人工校正或重新实现

3. 颜色分类：15%准确度
   - 历史文档墨迹褪色成灰色
   - 完全不可用

### 代码统计

| 模块 | 文件 | 行数 |
|------|------|------|
| 表格检测 | utils/table_detector.py | 471 |
| 文字分类 | utils/text_classifier.py | 143 |
| 颜色分类 | utils/color_classifier.py | 390 |
| 亮度分类 | utils/brightness_classifier.py | 280 |
| 墨迹分类 | utils/historical_doc_classifier.py | 320 |
| Web后端 | app.py | 154 |
| 前端 | static/ + templates/ | ~500 |
| 测试工具 | test_scripts/ | ~400 |
| 总计 | | ~2658 |

### 失败统计

6天开发周期，12次提交：
- 成功：1个功能（表格分离）
- 失败：6次尝试
  - 形态学特征分类
  - 图像增强+形态学
  - EasyOCR+位置分类（勉强）
  - 颜色自适应聚类
  - 亮度聚类
  - 墨迹深度分类

---

## 七、经验教训

### 技术选型

1. 简单方案不一定有效
   - 位置分类（93行）比形态学（321行）效果好
   - 但依然达不到要求

2. 了解问题域比算法更重要
   - 花了3天调整形态学特征阈值
   - 最终发现历史文档根本不适合这种方法

3. 不要过度优化
   - 从"毛笔书法级别"的严格阈值可以看出
   - 即使调到极端也无济于事

---

## 八、后续建议

### 表格分离

可以直接使用，效果可以接受。

可能的改进：
- 添加倾斜校正
- 支持嵌套表格
- 表格结构化解析（提取单元格内容为CSV）

### 文字分类

短期方案：
- 使用EasyOCR + 位置分类（60%）
- 人工校正错误分类

长期方案：
- 收集200-500张历史文档样本
- 人工标注手写/印刷体
- 训练轻量级CNN（如MobileNet）
- 预期准确度80-90%

现实方案：
- 对于历史文档数字化项目
- 自动分类 + 人工审核是行业标准
- 完全自动化不现实

### 颜色分类

对历史文档放弃，只适用于：
- 彩色扫描的现代文档
- 墨迹未褪色的文档
- 有明显颜色差异的文档

---

## 九、附录

### 关键文件位置

表格检测核心算法：
- utils/table_detector.py:145-202（内容密度分析）
- utils/table_detector.py:204-342（表格区域识别）

文字分类核心算法：
- utils/text_classifier.py:26-73（EasyOCR检测）
- utils/text_classifier.py:74-101（位置分类策略）

颜色分类核心算法：
- utils/color_classifier.py:51-87（颜色提取）
- utils/color_classifier.py:125-299（K-Means聚类）

### 测试命令

```bash
# 表格分离
python app.py  # 访问 http://localhost:5000

# 手写体分类独立测试
python classify_easyocr.py Pictures/原始.jpg

# 颜色分类测试
export PYTHONPATH=.
python test_scripts/color_classify_demo.py Pictures/原始.jpg --debug

# 亮度分类测试
python test_scripts/brightness_classify_demo.py Pictures/原始.jpg --debug

# 墨迹深度分类测试
python test_scripts/historical_classify_demo.py Pictures/原始.jpg
```

### 参数调整

表格检测参数（utils/table_detector.py）：
```python
# 形态学核大小
horizontal_kernel = (40, 1)
vertical_kernel = (1, 40)

# Hough变换参数
threshold = 50
minLineLength = 50
maxLineGap = 20

# 线条合并阈值
h_threshold = 5  # 水平线
v_threshold = 10  # 垂直线

# 内容密度阈值
empty_density = 0.01
title_density = 0.20
title_components = 30
```

文字分类参数（utils/text_classifier.py）：
```python
# 位置分界线
split_ratio = 0.45  # 45%

# 异常框过滤
max_aspect_ratio = 5
min_aspect_ratio = 0.2
```

颜色分类参数（utils/color_classifier.py）：
```python
# 聚类数范围
auto_k_range = (2, 6)

# 颜色空间
color_space = 'lab'  # 或 'rgb', 'hsv'

# 最小饱和度
min_saturation = 10
```

---

